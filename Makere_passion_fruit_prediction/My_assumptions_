I will be using faster rcnn as implementation concept to build my approach
RCNN:
https://github.com/ravirajsinh45/implementation_of_RCNN

here is the link to the competition: https://zindi.africa/competitions/makerere-passion-fruit-disease-detection-challenge

But it looks like rcnn are not end to end trainable detectors so let's check out a better approach:

link: https://www.pyimagesearch.com/2020/10/05/object-detection-bounding-box-regression-with-keras-tensorflow-and-deep-learning/

We will try this one for multiclass, classification and object detection: https://www.pyimagesearch.com/2020/10/12/multi-class-object-detection-and-bounding-box-regression-with-keras-tensorflow-and-deep-learning/


Let's see how to tune faster RCNN models to improve performance


https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/

https://towardsdatascience.com/getting-started-with-albumentation-winning-deep-learning-image-augmentation-technique-in-pytorch-47aaba0ee3f8

https://www.kaggle.com/reighns/augmentations-data-cleaning-and-bounding-boxes

now research paper...!

https://pypi.org/project/pyspectra/

Use this same approach for UNICEF [Target MAE of ~0.20 and below if possible]

1. Model exploration
  - With Mobilenetv2 I got a score of 0.377777 LB
    densenet169 and resnet50 are too large backbones for faster RCNN
  - with Resnet18 I got a score of 0.3489 LB a 0.03 drop compared to Mobilenetv2.
  - with Resnet34 I got almost similar score ~0.3505 LB
  - [conclusion] we ended up choosing both resnet18 and resnet34 as backbones for our Fast-RCNN
2. Data Processing
  - Plan to do heavy augmentation : Heavy augmentation doesn't work well.
  - Mixup
3. Hyper-parameter tuning.
  - Aspect ratio also gives some slight improvement in the aspect ratio column when : (0.5, 1.0,2.0,2.5) gives a LB ~ 0.33



